{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSPD_Project_Phase4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b322027681f412c99d1d8bfc69f0f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_37ab9e678aa64c6a876bfd28cb21b470",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d76f40fd97541da80285c2ca44de754",
              "IPY_MODEL_cc43c3c252f54c29a8368414858d5abf"
            ]
          }
        },
        "37ab9e678aa64c6a876bfd28cb21b470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d76f40fd97541da80285c2ca44de754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7fddb3f465741248deff3d5c50de772",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92f13bdee2464943ab90048cb85dd0a2"
          }
        },
        "cc43c3c252f54c29a8368414858d5abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c897c8951dc4664824193c9152bcd03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [10:15&lt;00:00, 1.28s/B]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a95a0ca31e44b4498986e02db081eed"
          }
        },
        "b7fddb3f465741248deff3d5c50de772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92f13bdee2464943ab90048cb85dd0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c897c8951dc4664824193c9152bcd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a95a0ca31e44b4498986e02db081eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c0145c69f4f4f38b843d51dba909a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04859bdf9f7748688ab43f18e802a7ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ce915e265094eedbf5c1b3781a62a04",
              "IPY_MODEL_77c9c2d8db4048e8a3096b7bf77b4ec8"
            ]
          }
        },
        "04859bdf9f7748688ab43f18e802a7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ce915e265094eedbf5c1b3781a62a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57a7a92c423d474eb481b66b8fda5a95",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_416537ff4a694a5583b19fc091b0ba38"
          }
        },
        "77c9c2d8db4048e8a3096b7bf77b4ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d843691ee6d4cf294c6ce45e651517d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 1.71MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fd3a4b46ad24c749416aeb959653dfe"
          }
        },
        "57a7a92c423d474eb481b66b8fda5a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "416537ff4a694a5583b19fc091b0ba38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d843691ee6d4cf294c6ce45e651517d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fd3a4b46ad24c749416aeb959653dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6900dfd0561048ea88a365340d578f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c667a2174e0b4ae59d9d4ae16308eee5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2ec781ae6fe4141b34024ff411f6e0a",
              "IPY_MODEL_aa587b8741d543dd9ad8234160c50870"
            ]
          }
        },
        "c667a2174e0b4ae59d9d4ae16308eee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2ec781ae6fe4141b34024ff411f6e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b6ee33a7b2e4d8f97cfd04475051f96",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c5495e506d84299bb7b3333ca930f65"
          }
        },
        "aa587b8741d543dd9ad8234160c50870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a13c7d39181f450a94c9a2088c99b4c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:04&lt;00:00, 94.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bd2b33cd56a42c299254cb6bbcb2646"
          }
        },
        "8b6ee33a7b2e4d8f97cfd04475051f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c5495e506d84299bb7b3333ca930f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a13c7d39181f450a94c9a2088c99b4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bd2b33cd56a42c299254cb6bbcb2646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjEPDEIwbikM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db60f8aa-f391-468f-8b9f-59568f9db818"
      },
      "source": [
        "!pip install -q colored\n",
        "!pip install transformers==3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import colored\n",
        "import re\n",
        "from colored import fg, bg, attr\n",
        "import os\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "import torch\n",
        "import torch_xla\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torch.multiprocessing import Pipe, Process\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences as pad\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▉                          | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20kB 22.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 30kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for colored (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n",
            "Collecting cloud-tpu-client==0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting torch-xla==1.8.1\n",
            "\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl (145.0MB)\n",
            "\u001b[K     |████████████████████████████████| 145.0MB 93kB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.30.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (56.1.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n",
            "\u001b[31mERROR: earthengine-api 0.1.266 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client, torch-xla\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UKO7r32xljM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "59be3db4-d632-459b-f246-3c9fb7e96d4a"
      },
      "source": [
        "#!python pytorch-xla-env-setup.py\n",
        "#!pip install torch\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "import torch\n",
        "import torch_xla\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torch.multiprocessing import Pipe, Process\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "#from transformers import RobertaModel, RobertaTokenizer\n",
        "#from transformers import RobertaConfig, RobertaModel\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences as pad\n",
        "!pip install boto3\n",
        "# # loading dataset\n",
        "# test_data = pd.read_csv('/content/sample_data/test.csv')\n",
        "# train_data = pd.read_csv('/content/sample_data/train.csv')\n",
        "import boto3\n",
        "import sys\n",
        "import io\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/20/4294e37c3c6936c905f1e9da958c776d7fee54a4512bdb7706d69c8720e6/boto3-1.17.84-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 6.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.5MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.84\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/22/72c81d754bbcb128cba2ad88670c3c320e4594e6ddd8cca6512c3967108c/botocore-1.20.84-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 8.3MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/cd/1e2ec680ec7b09846dc6e605f5a7709dfb9d7128e51a026e7154e18a234e/urllib3-1.26.5-py2.py3-none-any.whl (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.84->boto3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.84->boto3) (1.15.0)\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: earthengine-api 0.1.266 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, urllib3, botocore, s3transfer, boto3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.17.84 botocore-1.20.84 jmespath-0.10.0 s3transfer-0.4.2 urllib3-1.26.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca0_O7KR_kBr"
      },
      "source": [
        "# working with pytorch\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "#from transformers import RobertaModel, RobertaTokenizer\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XV-SlBFjUi9",
        "outputId": "6ad9a801-e8c7-4a88-9079-3b467cdb2e6e"
      },
      "source": [
        "# deployed on aws cloud storage\n",
        "\n",
        "s3_client =boto3.client('s3')\n",
        "s3_bucket_name='dspd-data-science'\n",
        "s3 = boto3.resource('s3',\n",
        "                    aws_access_key_id= 'AKIA4HGHG44HSWHZGMQV',\n",
        "                    aws_secret_access_key='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')\n",
        "\n",
        "my_bucket=s3.Bucket(s3_bucket_name)\n",
        "bucket_list = []\n",
        "for file in my_bucket.objects.filter(Prefix = 'train_data'):\n",
        "    file_name=file.key\n",
        "    if file_name.find(\".csv\")!=-1:\n",
        "        bucket_list.append(file.key)\n",
        "length_bucket_list=print(len(bucket_list))\n",
        "\n",
        "if sys.version_info[0] < 3:\n",
        "    from StringIO import StringIO  # Python 2.x\n",
        "else:\n",
        "    from io import StringIO  \n",
        "training_files = []   # Initializing empty list of dataframes\n",
        "for file in bucket_list:\n",
        "    obj = s3.Object(s3_bucket_name,file)\n",
        "    data=obj.get()['Body'].read()\n",
        "    training_files.append(pd.read_csv(io.BytesIO(data), header=0, delimiter=\",\", low_memory=False))\n",
        "train_data = pd.DataFrame(training_files[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH8t8JX1xmTV"
      },
      "source": [
        "\n",
        "# describing dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "0qdHatJwy8ic",
        "outputId": "c14e0a00-09f9-4509-9afa-c842ca8cacfc"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... sentiment\n",
              "0  cb774db0d1  ...   neutral\n",
              "1  549e992a42  ...  negative\n",
              "2  088c60f138  ...  negative\n",
              "3  9642c003ef  ...  negative\n",
              "4  358bd9e861  ...  negative\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WKi_4-dzCDF",
        "outputId": "9bc4d5af-df39-43fb-a5bd-bd39fdaa74e8"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27981, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIxaMUdlxqac"
      },
      "source": [
        "# data preprocessing (tokenizing data, padding, pre-processing)\n",
        "#roBERTa model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljrMPQxtGF3g"
      },
      "source": [
        "Defining Hyperparameter in advance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AQgf_WzGLAQ"
      },
      "source": [
        "# defining hyperparameters\n",
        "\n",
        "EPOCHS = 6\n",
        "SPLIT = 0.8\n",
        "MAXLEN = 48\n",
        "DROP_RATE = 0.3\n",
        "np.random.seed(42)\n",
        "\n",
        "OUTPUT_UNITS = 3\n",
        "BATCH_SIZE = 384\n",
        "LR = (4e-5, 1e-2)\n",
        "ROBERTA_UNITS = 768\n",
        "VAL_BATCH_SIZE = 384\n",
        "\n",
        "MODEL_SAVE_PATH = '/content/sample_data/dspd_sentiment_analysis.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfi5jDrfR4Sb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "5b322027681f412c99d1d8bfc69f0f87",
            "37ab9e678aa64c6a876bfd28cb21b470",
            "3d76f40fd97541da80285c2ca44de754",
            "cc43c3c252f54c29a8368414858d5abf",
            "b7fddb3f465741248deff3d5c50de772",
            "92f13bdee2464943ab90048cb85dd0a2",
            "8c897c8951dc4664824193c9152bcd03",
            "7a95a0ca31e44b4498986e02db081eed",
            "4c0145c69f4f4f38b843d51dba909a7d",
            "04859bdf9f7748688ab43f18e802a7ba",
            "1ce915e265094eedbf5c1b3781a62a04",
            "77c9c2d8db4048e8a3096b7bf77b4ec8",
            "57a7a92c423d474eb481b66b8fda5a95",
            "416537ff4a694a5583b19fc091b0ba38",
            "8d843691ee6d4cf294c6ce45e651517d",
            "0fd3a4b46ad24c749416aeb959653dfe",
            "6900dfd0561048ea88a365340d578f75",
            "c667a2174e0b4ae59d9d4ae16308eee5",
            "f2ec781ae6fe4141b34024ff411f6e0a",
            "aa587b8741d543dd9ad8234160c50870",
            "8b6ee33a7b2e4d8f97cfd04475051f96",
            "7c5495e506d84299bb7b3333ca930f65",
            "a13c7d39181f450a94c9a2088c99b4c2",
            "2bd2b33cd56a42c299254cb6bbcb2646"
          ]
        },
        "outputId": "becb6461-8570-4ff8-d3b1-43576f831696"
      },
      "source": [
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model_name = 'roberta-base'\n",
        "\n",
        "#model_name = 'bert-base'\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_config(config=config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b322027681f412c99d1d8bfc69f0f87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c0145c69f4f4f38b843d51dba909a7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6900dfd0561048ea88a365340d578f75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePztRxtWJfSO"
      },
      "source": [
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.text = data.text\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sentiment = data.sentiment\n",
        "        self.sentiment_dict = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        #print(\"iteration: \",i)\n",
        "        start, finish = 0, 2\n",
        "        pg, tg = 'post', 'post'\n",
        "        tweet = str(self.text[i]).strip()\n",
        "        tweet_ids = self.tokenizer.encode(tweet)\n",
        "\n",
        "        attention_mask_idx = len(tweet_ids) - 1\n",
        "        if start not in tweet_ids: tweet_ids = start + tweet_ids\n",
        "        tweet_ids = pad([tweet_ids], maxlen=MAXLEN, value=1, padding=pg, truncating=tg)\n",
        "\n",
        "        attention_mask = np.zeros(MAXLEN)\n",
        "        attention_mask[1:attention_mask_idx] = 1\n",
        "        attention_mask = attention_mask.reshape((1, -1))\n",
        "        if finish not in tweet_ids: tweet_ids[-1], attention_mask[-1] = finish, start\n",
        "        #print(self.sentiment[i])    \n",
        "        sentiment = [self.sentiment_dict[self.sentiment[i]]]\n",
        "        sentiment = torch.FloatTensor(to_categorical(sentiment, num_classes=3))\n",
        "        return sentiment, torch.LongTensor(tweet_ids), torch.LongTensor(attention_mask)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo5ONhokWG0K"
      },
      "source": [
        "#TweetDataset(train_data, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2y2gDV1IQw8"
      },
      "source": [
        "class Roberta(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Roberta, self).__init__()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.drop = nn.Dropout(DROP_RATE)\n",
        "        self.roberta = RobertaModel.from_pretrained(model)\n",
        "        self.dense = nn.Linear(ROBERTA_UNITS, OUTPUT_UNITS)\n",
        "        \n",
        "    def forward(self, inp, att):\n",
        "        inp = inp.view(-1, MAXLEN)\n",
        "        _, self.feat = self.roberta(inp, att)\n",
        "        return self.softmax(self.dense(self.drop(self.feat)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ZiK-aHJFzA"
      },
      "source": [
        " model = 'roberta-base'\n",
        " tokenizer = RobertaTokenizer.from_pretrained(model)\n",
        "def cel(inp, target):\n",
        "    _, labels = target.max(dim=1)\n",
        "    return nn.CrossEntropyLoss()(inp, labels)*len(inp)\n",
        "\n",
        "def accuracy(inp, target):\n",
        "    inp_ind = inp.max(axis=1).indices\n",
        "    target_ind = target.max(axis=1).indices\n",
        "    return (inp_ind == target_ind).float().sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHb27zPVdcth"
      },
      "source": [
        "def print_metric(data, batch, epoch, start, end, metric, typ):\n",
        "    t = typ, metric, \"%s\", data, \"%s\"\n",
        "    if typ == \"Train\": pre = \"BATCH %s\" + str(batch-1) + \"%s  \"\n",
        "    if typ == \"Val\": pre = \"\\nEPOCH %s\" + str(epoch+1) + \"%s  \"\n",
        "    time = np.round(end - start, 1); time = \"Time: %s{}%s s\".format(time)\n",
        "    fonts = [(fg(211), attr('reset')), (fg(212), attr('reset')), (fg(213), attr('reset'))]\n",
        "    xm.master_print(pre % fonts[0] + \"{} {}: {}{}{}\".format(*t) % fonts[1] + \"  \" + time % fonts[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Sc83iCJk5n"
      },
      "source": [
        "\n",
        "\n",
        "global val_losses; global train_losses\n",
        "global val_accuracies; global train_accuracies\n",
        "\n",
        "def train_fn(train_df):\n",
        "    train_df = shuffle(train_df)\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "    split = np.int32(SPLIT*len(train_df))\n",
        "    val_df, train_df = train_df[split:], train_df[:split]\n",
        "\n",
        "    val_df = val_df.reset_index(drop=True)\n",
        "    val_dataset = TweetDataset(val_df, tokenizer)\n",
        "    val_sampler = DistributedSampler(val_dataset, num_replicas=8,\n",
        "                                     rank=xm.get_ordinal(),shuffle=True)\n",
        "    \n",
        "    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE,\n",
        "                            sampler=val_sampler, num_workers=0, drop_last=True)\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    train_dataset = TweetDataset(train_df, tokenizer)\n",
        "    train_sampler = DistributedSampler(train_dataset, num_replicas=8,\n",
        "                                       rank=xm.get_ordinal(), shuffle=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                              sampler=train_sampler, num_workers=0, drop_last=True)\n",
        "    device = xm.xla_device()\n",
        "    network = Roberta().to(device)\n",
        "    optimizer = Adam([{'params': network.dense.parameters(), 'lr': LR[1]},\n",
        "                      {'params': network.roberta.parameters(), 'lr': LR[0]}])\n",
        "\n",
        "    val_losses, val_accuracies = [], []\n",
        "    train_losses, train_accuracies = [], []\n",
        "    \n",
        "    start = time.time()\n",
        "    xm.master_print(\"STARTING TRAINING ...\\n\")\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        batch = 1\n",
        "        network.train()\n",
        "        fonts = (fg(48), attr('reset'))\n",
        "        xm.master_print((\"EPOCH %s\" + str(epoch+1) + \"%s\") % fonts)\n",
        "\n",
        "        val_parallel = pl.ParallelLoader(val_loader, [device]).per_device_loader(device)\n",
        "        train_parallel = pl.ParallelLoader(train_loader, [device]).per_device_loader(device)\n",
        "        \n",
        "        for train_batch in train_parallel:\n",
        "            train_targ, train_in, train_att = train_batch\n",
        "            \n",
        "            network = network.to(device)\n",
        "            train_in = train_in.to(device)\n",
        "            train_att = train_att.to(device)\n",
        "            train_targ = train_targ.to(device)\n",
        "\n",
        "            train_preds = network.forward(train_in, train_att)\n",
        "            train_loss = cel(train_preds, train_targ.squeeze(dim=1))/len(train_in)\n",
        "            train_accuracy = accuracy(train_preds, train_targ.squeeze(dim=1))/len(train_in)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "            \n",
        "            end = time.time()\n",
        "            batch = batch + 1\n",
        "            acc = np.round(train_accuracy.item(), 3)\n",
        "            print_metric(acc, batch, None, start, end, metric=\"acc\", typ=\"Train\")\n",
        "\n",
        "        val_loss, val_accuracy, val_points = 0, 0, 0\n",
        "\n",
        "        network.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_batch in val_parallel:\n",
        "                targ, val_in, val_att = val_batch\n",
        "\n",
        "                targ = targ.to(device)\n",
        "                val_in = val_in.to(device)\n",
        "                val_att = val_att.to(device)\n",
        "                network = network.to(device)\n",
        "            \n",
        "                val_points += len(targ)\n",
        "                pred = network.forward(val_in, val_att)\n",
        "                val_loss += cel(pred, targ.squeeze(dim=1)).item()\n",
        "                val_accuracy += accuracy(pred, targ.squeeze(dim=1)).item()\n",
        "        \n",
        "        end = time.time()\n",
        "        val_loss /= val_points\n",
        "        val_accuracy /= val_points\n",
        "        acc = xm.mesh_reduce('acc', val_accuracy, lambda x: sum(x)/len(x))\n",
        "        print_metric(np.round(acc, 3), None, epoch, start, end, metric=\"acc\", typ=\"Val\")\n",
        "    \n",
        "        xm.master_print(\"\")\n",
        "        val_losses.append(val_loss); train_losses.append(train_loss.item())\n",
        "        val_accuracies.append(val_accuracy); train_accuracies.append(train_accuracy.item())\n",
        "\n",
        "    xm.master_print(\"ENDING TRAINING ...\")\n",
        "    xm.save(network.state_dict(), MODEL_SAVE_PATH); del network; gc.collect()\n",
        "\n",
        "    metric_names = ['val_loss_', 'train_loss_', 'val_acc_', 'train_acc_']\n",
        "    metric_lists = [val_losses, train_losses, val_accuracies, train_accuracies]\n",
        "    \n",
        "    for i, metric_list in enumerate(metric_lists):\n",
        "        for j, metric_value in enumerate(metric_list):\n",
        "            torch.save(metric_value, metric_names[i] + str(j) + '.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFTy04wfJ7af",
        "outputId": "8a1fd737-97c7-411c-8f94-7dae73ab7498"
      },
      "source": [
        "FLAGS = {}\n",
        "def _mp_fn(rank, flags): train_fn(train_data)\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "STARTING TRAINING ...\n",
            "\n",
            "EPOCH \u001b[38;5;48m1\u001b[0m\n",
            "BATCH \u001b[38;5;211m1\u001b[0m  Train acc: \u001b[38;5;212m0.305\u001b[0m  Time: \u001b[38;5;213m12.1\u001b[0m s\n",
            "BATCH \u001b[38;5;211m2\u001b[0m  Train acc: \u001b[38;5;212m0.388\u001b[0m  Time: \u001b[38;5;213m132.7\u001b[0m s\n",
            "BATCH \u001b[38;5;211m3\u001b[0m  Train acc: \u001b[38;5;212m0.388\u001b[0m  Time: \u001b[38;5;213m241.4\u001b[0m s\n",
            "BATCH \u001b[38;5;211m4\u001b[0m  Train acc: \u001b[38;5;212m0.414\u001b[0m  Time: \u001b[38;5;213m243.5\u001b[0m s\n",
            "BATCH \u001b[38;5;211m5\u001b[0m  Train acc: \u001b[38;5;212m0.383\u001b[0m  Time: \u001b[38;5;213m245.4\u001b[0m s\n",
            "BATCH \u001b[38;5;211m6\u001b[0m  Train acc: \u001b[38;5;212m0.263\u001b[0m  Time: \u001b[38;5;213m247.3\u001b[0m s\n",
            "BATCH \u001b[38;5;211m7\u001b[0m  Train acc: \u001b[38;5;212m0.286\u001b[0m  Time: \u001b[38;5;213m249.0\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;211m1\u001b[0m  Val acc: \u001b[38;5;212m0.404\u001b[0m  Time: \u001b[38;5;213m274.3\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;48m2\u001b[0m\n",
            "BATCH \u001b[38;5;211m1\u001b[0m  Train acc: \u001b[38;5;212m0.411\u001b[0m  Time: \u001b[38;5;213m280.7\u001b[0m s\n",
            "BATCH \u001b[38;5;211m2\u001b[0m  Train acc: \u001b[38;5;212m0.391\u001b[0m  Time: \u001b[38;5;213m285.2\u001b[0m s\n",
            "BATCH \u001b[38;5;211m3\u001b[0m  Train acc: \u001b[38;5;212m0.388\u001b[0m  Time: \u001b[38;5;213m287.1\u001b[0m s\n",
            "BATCH \u001b[38;5;211m4\u001b[0m  Train acc: \u001b[38;5;212m0.409\u001b[0m  Time: \u001b[38;5;213m288.9\u001b[0m s\n",
            "BATCH \u001b[38;5;211m5\u001b[0m  Train acc: \u001b[38;5;212m0.385\u001b[0m  Time: \u001b[38;5;213m290.8\u001b[0m s\n",
            "BATCH \u001b[38;5;211m6\u001b[0m  Train acc: \u001b[38;5;212m0.44\u001b[0m  Time: \u001b[38;5;213m292.6\u001b[0m s\n",
            "BATCH \u001b[38;5;211m7\u001b[0m  Train acc: \u001b[38;5;212m0.43\u001b[0m  Time: \u001b[38;5;213m294.4\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;211m2\u001b[0m  Val acc: \u001b[38;5;212m0.42\u001b[0m  Time: \u001b[38;5;213m296.8\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;48m3\u001b[0m\n",
            "BATCH \u001b[38;5;211m1\u001b[0m  Train acc: \u001b[38;5;212m0.414\u001b[0m  Time: \u001b[38;5;213m303.3\u001b[0m s\n",
            "BATCH \u001b[38;5;211m2\u001b[0m  Train acc: \u001b[38;5;212m0.391\u001b[0m  Time: \u001b[38;5;213m305.5\u001b[0m s\n",
            "BATCH \u001b[38;5;211m3\u001b[0m  Train acc: \u001b[38;5;212m0.385\u001b[0m  Time: \u001b[38;5;213m307.6\u001b[0m s\n",
            "BATCH \u001b[38;5;211m4\u001b[0m  Train acc: \u001b[38;5;212m0.451\u001b[0m  Time: \u001b[38;5;213m309.4\u001b[0m s\n",
            "BATCH \u001b[38;5;211m5\u001b[0m  Train acc: \u001b[38;5;212m0.466\u001b[0m  Time: \u001b[38;5;213m311.3\u001b[0m s\n",
            "BATCH \u001b[38;5;211m6\u001b[0m  Train acc: \u001b[38;5;212m0.393\u001b[0m  Time: \u001b[38;5;213m313.1\u001b[0m s\n",
            "BATCH \u001b[38;5;211m7\u001b[0m  Train acc: \u001b[38;5;212m0.549\u001b[0m  Time: \u001b[38;5;213m315.0\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;211m3\u001b[0m  Val acc: \u001b[38;5;212m0.606\u001b[0m  Time: \u001b[38;5;213m317.3\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;48m4\u001b[0m\n",
            "BATCH \u001b[38;5;211m1\u001b[0m  Train acc: \u001b[38;5;212m0.565\u001b[0m  Time: \u001b[38;5;213m324.0\u001b[0m s\n",
            "BATCH \u001b[38;5;211m2\u001b[0m  Train acc: \u001b[38;5;212m0.596\u001b[0m  Time: \u001b[38;5;213m326.1\u001b[0m s\n",
            "BATCH \u001b[38;5;211m3\u001b[0m  Train acc: \u001b[38;5;212m0.628\u001b[0m  Time: \u001b[38;5;213m328.1\u001b[0m s\n",
            "BATCH \u001b[38;5;211m4\u001b[0m  Train acc: \u001b[38;5;212m0.607\u001b[0m  Time: \u001b[38;5;213m329.9\u001b[0m s\n",
            "BATCH \u001b[38;5;211m5\u001b[0m  Train acc: \u001b[38;5;212m0.659\u001b[0m  Time: \u001b[38;5;213m331.7\u001b[0m s\n",
            "BATCH \u001b[38;5;211m6\u001b[0m  Train acc: \u001b[38;5;212m0.643\u001b[0m  Time: \u001b[38;5;213m333.5\u001b[0m s\n",
            "BATCH \u001b[38;5;211m7\u001b[0m  Train acc: \u001b[38;5;212m0.688\u001b[0m  Time: \u001b[38;5;213m335.4\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;211m4\u001b[0m  Val acc: \u001b[38;5;212m0.701\u001b[0m  Time: \u001b[38;5;213m337.8\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;48m5\u001b[0m\n",
            "BATCH \u001b[38;5;211m1\u001b[0m  Train acc: \u001b[38;5;212m0.677\u001b[0m  Time: \u001b[38;5;213m344.4\u001b[0m s\n",
            "BATCH \u001b[38;5;211m2\u001b[0m  Train acc: \u001b[38;5;212m0.69\u001b[0m  Time: \u001b[38;5;213m346.7\u001b[0m s\n",
            "BATCH \u001b[38;5;211m3\u001b[0m  Train acc: \u001b[38;5;212m0.698\u001b[0m  Time: \u001b[38;5;213m348.7\u001b[0m s\n",
            "BATCH \u001b[38;5;211m4\u001b[0m  Train acc: \u001b[38;5;212m0.727\u001b[0m  Time: \u001b[38;5;213m350.5\u001b[0m s\n",
            "BATCH \u001b[38;5;211m5\u001b[0m  Train acc: \u001b[38;5;212m0.74\u001b[0m  Time: \u001b[38;5;213m352.2\u001b[0m s\n",
            "BATCH \u001b[38;5;211m6\u001b[0m  Train acc: \u001b[38;5;212m0.721\u001b[0m  Time: \u001b[38;5;213m354.2\u001b[0m s\n",
            "BATCH \u001b[38;5;211m7\u001b[0m  Train acc: \u001b[38;5;212m0.724\u001b[0m  Time: \u001b[38;5;213m356.0\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;211m5\u001b[0m  Val acc: \u001b[38;5;212m0.728\u001b[0m  Time: \u001b[38;5;213m358.5\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;48m6\u001b[0m\n",
            "BATCH \u001b[38;5;211m1\u001b[0m  Train acc: \u001b[38;5;212m0.711\u001b[0m  Time: \u001b[38;5;213m365.2\u001b[0m s\n",
            "BATCH \u001b[38;5;211m2\u001b[0m  Train acc: \u001b[38;5;212m0.732\u001b[0m  Time: \u001b[38;5;213m367.3\u001b[0m s\n",
            "BATCH \u001b[38;5;211m3\u001b[0m  Train acc: \u001b[38;5;212m0.737\u001b[0m  Time: \u001b[38;5;213m369.4\u001b[0m s\n",
            "BATCH \u001b[38;5;211m4\u001b[0m  Train acc: \u001b[38;5;212m0.711\u001b[0m  Time: \u001b[38;5;213m371.2\u001b[0m s\n",
            "BATCH \u001b[38;5;211m5\u001b[0m  Train acc: \u001b[38;5;212m0.75\u001b[0m  Time: \u001b[38;5;213m373.2\u001b[0m s\n",
            "BATCH \u001b[38;5;211m6\u001b[0m  Train acc: \u001b[38;5;212m0.753\u001b[0m  Time: \u001b[38;5;213m375.1\u001b[0m s\n",
            "BATCH \u001b[38;5;211m7\u001b[0m  Train acc: \u001b[38;5;212m0.76\u001b[0m  Time: \u001b[38;5;213m377.0\u001b[0m s\n",
            "\n",
            "EPOCH \u001b[38;5;211m6\u001b[0m  Val acc: \u001b[38;5;212m0.748\u001b[0m  Time: \u001b[38;5;213m379.4\u001b[0m s\n",
            "\n",
            "ENDING TRAINING ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lenp02PDUN-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c52113b-4343-41b2-dad6-bc13458e95ed"
      },
      "source": [
        "network = Roberta()\n",
        "\n",
        "network.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UgC1CKVbSId"
      },
      "source": [
        "device = xm.xla_device()\n",
        "network = network.to(device)\n",
        "def predict_sentiment(tweet):\n",
        "    pg, tg = 'post', 'post'\n",
        "    tweet_ids = tokenizer.encode(tweet.strip())\n",
        "    sent = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
        "\n",
        "    att_mask_idx = len(tweet_ids) - 1\n",
        "    if 0 not in tweet_ids: tweet_ids = 0 + tweet_ids\n",
        "    tweet_ids = pad([tweet_ids], maxlen=MAXLEN, value=1, padding=pg, truncating=tg)\n",
        "    # device = xm.xla_device()\n",
        "    att_mask = np.zeros(MAXLEN)\n",
        "    att_mask[1:att_mask_idx] = 1\n",
        "    att_mask = att_mask.reshape((1, -1))\n",
        "    if 2 not in tweet_ids: tweet_ids[-1], att_mask[-1] = 2, 0\n",
        "    tweet_ids, att_mask = torch.LongTensor(tweet_ids), torch.LongTensor(att_mask)\n",
        "    return sent[np.argmax(network.forward(tweet_ids.to(device), att_mask.to(device)).detach().cpu().numpy())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "58vnEdTObINO",
        "outputId": "9637f072-0561-41a4-872e-e1216b4b6834"
      },
      "source": [
        "\n",
        "predict_sentiment(\"You are disgusting ...\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfOX43LPAnKO"
      },
      "source": [
        "Google Drive was used to mount and get model.pt file of the previous running file. Since model file was too big and it takes much time to upload we have tested code one time and we have commented out now because of separate drives. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6VeG3NI6SwN"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/MyDrive/DSPD')\n",
        "# %cd /content/gdrive/MyDrive/DSPD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BlM1JYNLOvK"
      },
      "source": [
        "val_losses = [torch.load('val_loss_{}.pt'.format(i)) for i in range(EPOCHS)]\n",
        "train_losses = [torch.load('train_loss_{}.pt'.format(i)) for i in range(EPOCHS)]\n",
        "val_accuracies = [torch.load('val_acc_{}.pt'.format(i)) for i in range(EPOCHS)]\n",
        "train_accuracies = [torch.load('train_acc_{}.pt'.format(i)) for i in range(EPOCHS)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MAEffoFkLWZL",
        "outputId": "847e98f0-47a3-48bc-e36f-0c8e7507d9c3"
      },
      "source": [
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.arange(1, len(val_accuracies)+1),\n",
        "                         y=val_accuracies, mode=\"lines+markers\", name=\"val\",\n",
        "                         marker=dict(color=\"hotpink\", line=dict(width=.5,\n",
        "                                                                color='rgb(0, 0, 0)'))))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.arange(1, len(train_accuracies)+1),\n",
        "                         y=train_accuracies, mode=\"lines+markers\", name=\"train\",\n",
        "                         marker=dict(color=\"mediumorchid\", line=dict(width=.5,\n",
        "                                                                     color='rgb(0, 0, 0)'))))\n",
        "\n",
        "fig.update_layout(xaxis_title=\"Epochs\", yaxis_title=\"Accuracy\",\n",
        "                  title_text=\"Accuracy vs. Epochs\", template=\"plotly_white\", paper_bgcolor=\"#f0f0f0\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"b0fe0bb6-f78d-4ca8-917d-1b022ce2d82f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"b0fe0bb6-f78d-4ca8-917d-1b022ce2d82f\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'b0fe0bb6-f78d-4ca8-917d-1b022ce2d82f',\n",
              "                        [{\"marker\": {\"color\": \"hotpink\", \"line\": {\"color\": \"rgb(0, 0, 0)\", \"width\": 0.5}}, \"mode\": \"lines+markers\", \"name\": \"val\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6], \"y\": [0.3802083333333333, 0.390625, 0.5703125, 0.6901041666666666, 0.7135416666666666, 0.7473958333333334]}, {\"marker\": {\"color\": \"mediumorchid\", \"line\": {\"color\": \"rgb(0, 0, 0)\", \"width\": 0.5}}, \"mode\": \"lines+markers\", \"name\": \"train\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6], \"y\": [0.2864583432674408, 0.4244791865348816, 0.5494791865348816, 0.6901041865348816, 0.7265625, 0.7604166865348816]}],\n",
              "                        {\"paper_bgcolor\": \"#f0f0f0\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#C8D4E3\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy vs. Epochs\"}, \"xaxis\": {\"title\": {\"text\": \"Epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"Accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b0fe0bb6-f78d-4ca8-917d-1b022ce2d82f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccDWvyJ-py3-"
      },
      "source": [
        "**Model Interpretability with Captum**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVp4G5eMjXU-",
        "outputId": "bf6af8c3-306d-4847-925b-4f089d8ceea9"
      },
      "source": [
        "!pip install captum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum) (1.8.1+cu101)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhvdg0vkjpDC"
      },
      "source": [
        "from captum.attr import (\n",
        "    GradientShap,\n",
        "    DeepLift,\n",
        "    DeepLiftShap,\n",
        "    IntegratedGradients,\n",
        "    LayerConductance,\n",
        "    NeuronConductance,\n",
        "    NoiseTunnel,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PpYd87XnGId"
      },
      "source": [
        "torch.manual_seed(123)\n",
        "np.random.seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gpzx1qinGxc"
      },
      "source": [
        "input = torch.rand(2, 3)\n",
        "baseline = torch.zeros(2, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVkAbO6Dn4Pr"
      },
      "source": [
        "gs = GradientShap(network)\n",
        "\n",
        "# We define a distribution of baselines and draw `n_samples` from that\n",
        "# distribution in order to estimate the expectations of gradients across all baselines\n",
        "baseline_dist = torch.randn(10, 3) * 0.001\n",
        "attributions, delta = gs.attribute(input, stdevs=0.09, n_samples=4, baselines=baseline_dist,\n",
        "                                   target=0, return_convergence_delta=True)\n",
        "print('GradientShap Attributions:', attributions)\n",
        "print('Convergence Delta:', delta)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}